{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema\n",
    "\n",
    "## Deadlines\n",
    "12 november labb  \n",
    "26 november seminarie  \n",
    "28 november börjar nästa kurs  \n",
    "29 november personlig inlämning  \n",
    "\n",
    "# KPI\n",
    "\n",
    "Key performance indicator. \n",
    "\n",
    "- mätbara  \n",
    "- kritiska för framgång  \n",
    "- kopplade till affärsmål  \n",
    "- begränsad till 5-8 mätvärden  \n",
    "- applicerbara för hela företaget  \n",
    "\n",
    "Att mäta produktivitet på antalet jobbade timmar är problematiskt.  \n",
    "\n",
    "Mätbarhet inom mjukvaruutveckling är komplext. Prestation är oftast tid, hur snabba är vi, hur lång tid tar det. Folk kan känna sig utpekade med personliga KPI:er. Vissa KPI:er ses som absoluta vilket kan vara problematiskt. Ofta agila metoder. I stället för personliga KPI:er så har teamen poäng, hur många poäng är det kvar på en uppgift. Men då blir det lite svårt att identifiera trender. Bristiande tillit mellan anställda och ledning när mer och mer mäts.  \n",
    "\n",
    "Encoding är ett sätt för AI att välja ut KPI:er.  \n",
    "\n",
    "Recurrent monetisation.  \n",
    "\n",
    "Hur spåras prestandan hos ett AI-system? R har inte hittat något bra. Än så länge bara kundnöjdhet (tillit etc). Har mer med AI överlag att göra och inte själva produkten. T ex en LLM, hur bra är output? Eftersom vi inte kan återskapa den serie operationer som gav det svaret så är det oerhört svårt att mäta. Klassificeringar är enklare, översättningar är svårare.  \n",
    "\n",
    "# continuing with 241104.dash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
